<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Daniel Russo &ndash; Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Site Map</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="talk_videos.html">Talk&nbsp;Videos</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="docs/CV.pdf">Resume</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Daniel Russo &ndash; Research</h1>
</div>
<p>On Adaptivity and Confounding in Contextual Bandit Experiments. <br /> 
Daniel Russo and Chao Qin <br /> 
<i> Working paper (Status: posted soon) </i> <br /></p>
<p><a href="https://arxiv.org/abs/2007.11684"><b>Approximation Benefits of Policy Gradient Methods with Aggregated States.</b></a> <br />
Daniel Russo <br />
<i>Working paper (Status: major revision requested at Management Science) </i>  <br /></p>
<p><a href="https://arxiv.org/abs/1906.01786"><b>Global Optimality Guarantees For Policy Gradient Methods</b></a> <br />
Jalaj Bhandari and Daniel Russo <br />
<i>Working paper (Status: major revision requested at Operations Research)</i>  <br />
<a href="https://www.youtube.com/watch?v=7oejTicsuVY&amp;feature=emb_title">Talk link</a><br /></p>
<p><a href="http://proceedings.mlr.press/v130/bhandari21a.html"><b>On the Linear Convergence of Policy Gradient Methods for Finite MDPs</b></a> <br />
Jalaj Bhandari and Daniel Russo <br />
<i>Conference on Artificial Intelligence and Statistics (AISTATS), 2021</i> <br /></p>
<p><a href="https://arxiv.org/abs/2102.10025"><b>Learning to Stop with Surprisingly Few Samples</b></a> <br />
Tianyi Zhang, Daniel Russo, Assaf Zeevi <br />
<i>Appeared at COLT 2021, journal version in progress</i> <br /></p>
<p><a href="docs/futiliy_of_dynamics_merged.pdf"><b>On the Futility of Dynamics in Robust Mechanism Design</b></a><br />
Santiago Balseiro, Anthony Kim and Daniel Russo <br />  
<i>Operations Research, 2021</i> <br /></p>
<p><a href="docs/gittins.pdf"><b>A Note on the Equivalence of Upper Confidence Bounds and Gittins Indices for Patient Agents</b></a> <br />
Daniel Russo <br />
<i>Operations Research, 2021 </i>  <br /></p>
<p><a href="docs/TD_finite_time_merged.pdf"><b>A Finite Time Analysis of Temporal Difference Learning With Linear Function Approximation</b></a> <br />
Jalaj Bhandari, Daniel Russo, and Raghav Singal <br />
<i>Operations Research, 2021</i><br />
<i>Preliminary version appeared at COLT 2018</i><br />
<a href="https://www.youtube.com/watch?v=UWzybKYVjIo">Short talk link</a><br /></p>
<p><a href="https://arxiv.org/abs/1803.02855"><b>Satisficing in Time-Sensitive Bandit Learning</b></a><br />
Daniel Russo and Benjamin Van Roy <br />
<i>Mathematics of Operations Research (to appear)</i> <br /></p>
<p><a href="http://arxiv.org/abs/1906.02870"><b>Worst-Case Regret Bounds For Exploration Via Randomized Value Functions</b></a> <br />
Daniel Russo <br />
<i>NeurIPS 2019 </i>  <br /></p>
<p><a href="docs/TS_Tutorial.pdf"><b>A Tutorial on Thompson Sampling</b></a><br />
Daniel Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, and Zheng Wen <br />
<i>Foundations and Trends in Machine Learning, Vol. 11, No. 1, pp. 1-96, 2018.</i>  (<a href="https://github.com/iosband/ts_tutorial">code</a>)  <br /></p>
<p><a href="http://jmlr.org/papers/volume20/18-339/18-339.pdf"><b>Deep Exploration via Randomized Value Functions</b></a><br />
Ian Osband, Daniel Russo, Zheng Wen, and Benjamin Van Roy <br />
<i>Journal of Machine Learning Research, 2019</i> <br /></p>
<p><a href="https://arxiv.org/abs/1705.10033"><b>Improving the Expected Improvement Algorithm</b></a><br />
Chao Qin, Diego Klabjan and Daniel Russo <br />
<i>NeurIPS 2017</i><br /></p>
<p><a href="docs/best_arm_identification_body.pdf"><b>Simple Bayesian Algorithms for Best Arm Identification</b></a><br />
Daniel Russo<br />
<i>Operations Research, 2020</i><br /> 
<i>Prelimnary version appeared in COLT 2016</i><br /> <font color="FF0000">First place, INFORMS JFIG paper competition.<font color="000000"><br /> </p>
<p><a href="docs/information_usage.pdf"><b>Controling Bias in Adaptive Data Analysis Using Information Theory</b></a><br />
Daniel Russo and James Zou<br /> 
<i>IEEE Transaction on Information Theory, 2020</i><br /> 
<i>Preliminary version appeared at AISTATS 2016</i> <font color="FF0000">(full oral presentation; top 7% of submissions).<font color="000000"><br /> </p>
<p><a href="https://pubsonline.informs.org/doi/abs/10.1287/opre.2017.1663"><b>Learning to Optimize Via Information Directed Sampling</b></a><br />
Daniel Russo and Benjamin Van Roy<br /> 
<i>Operations Research, 2018</i><br /> 
<i>Prelimnary version appeared at NeurIPS 2014</i> <br /> <font color="FF0000">First place, INFORMS George Nicholson 2014 student paper competition.<font color="000000"><br /> </p>
<p><a href="http://www.jmlr.org/papers/volume17/14-087/14-087.pdf"><b>An Information-Theoretic Analysis of Thompson Sampling</b></a><br />
Daniel Russo and Benjamin Van Roy<br /> 
<i>Journal of Machine Learning Research, 2016</i><br /></p>
<p><a href="docs/Learning_to_Optimize.pdf"><b>Learning to Optimize Via Posterior Sampling</b></a><br />
Daniel Russo and Benjamin Van Roy<br /> 
<i>Mathematics of Operations Research. Vol. 39. No. 4, pp. 1221-1243, 2014.</i><br /></p>
<p><a href="docs/Eluder_Dimension.pdf"><b>Eluder Dimension and the Sample Complexity of Optimistic Exploration</b></a> <br />
Daniel Russo and Benjamin Van Roy<br />
<i>NeurIPS 2013</i> <font color="FF0000">(full oral presentation; top 1.4% of submissions).<font color="000000"><br /> </p>
<p><a href="docs/PSRL.pdf"><b>(More) Efficient Reinforcement Learning via Posterior Sampling</b></a> <br />
Ian Osband, Daniel Russo, and Benjamin Van Roy<br />
<i>NeurIPS 2013.</i> <br /></p>
<p><a href="docs/Welfare_Improving_Cascades_and_the_Effect_of_Noisy_Reviews.pdf"><b>Welfare-Improving Cascades and the Effect of Noisy Reviews</b></a> <br />
Nick Arnosti and Daniel Russo<br />
<i>WINE 2013.</i> <br /></p>
<div id="footer">
<div id="footer-text">
Page generated 2021-10-25 21:40:00 Cuba Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
