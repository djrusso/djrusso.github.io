<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Dan Russo &ndash; Teaching</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Site Map</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="teaching.html" class="current">Teaching</a></div>
<div class="menu-item"><a href="docs/CV.pdf">Resume</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Dan Russo &ndash; Teaching</h1>
</div>
<h2>OPNS 525: Learning in Sequential Decision Making</h2>
<h2>Course Overview</h2>
<p>This course offers an advanced introduction to topics at the intersection of statistical (machine) learning and sequential decision-making. A tentative course plan is as follows. We will begin by covering classic work on optimal hypothesis testing when data can be gathered sequentially and interactively. The second part of the class focuses on bandit learning and the design and analysis of algorithms that balance exploration/exploitation. The last part of the course introduces reinforcement learning, including methods for value function approximation and algorithms for efficient exploration. Students should have experience with mathematical proofs, coding for numerical computation, and the basics of statistics, optimization, dynamic programming, and stochastic processes.</p>
<h2>Course Logistics</h2>
<p>Tuesday/Thursday 2:00-3:300 PM <br />
Kellogg Global Hub 4302 <br />
<br /> 
Office Hours: Thursday 3:30-4:30 PM or by appointment <br />
Office: Kellogg Global Hub 4171</p>
<h2>Tentative Outline</h2>
<ol>
<li><p>Sequential and Active Hypothesis Testing</p>
<ol>
<li><p>Wald's sequential probability ratio test and optimal stopping</p>
</li>
<li><p>Chernoff's optimal sequential design of experiments for hypothesis testing</p>
</li></ol>
</li>
<li><p>Bandit Learning</p>
<ol>
<li><p>Upper Confidence Bound Algorithms</p>
</li>
<li><p>Thompson Sampling</p>
</li>
<li><p>Regret analysis</p>
</li>
<li><p>Applications to dynamic pricing and the shortest path problem</p>
</li></ol>
</li>
<li><p>Reinforcement Learning</p>
<ol>
<li><p>Value function learning: least-squares value iteration, temporal differences, and Q-learning</p>
</li>
<li><p>Parametric approximations to the value function</p>
</li>
<li><p>The exploration problem in RL</p>
</li>
</ol>

</li>
</ol>
<h1>Readings</h1>
<h3>Sequential and Active Hypothesis Testing</h3>
<ul>
<li><p><a href="docs/OPNS525\papers/Wald.pdf">Wald's original paper</a></p>
</li>
<li><p><a href="docs/OPNS525\papers/Chernoff.pdf">Chernoff's original paper</a> </p>
</li>
<li><p><a href="docs/OPNS525\papers/best_arm_identification.pdf">Chernoff's complexity measure in best-arm identification</a></p>
</li>
<li><p><a href="docs/OPNS525\papers/Capacity_of_info_processing.pdf">Chernoff's complexity measure in the capacity of info processing systems</a></p>
</li>
<li><p><a href="docs/OPNS525\papers/Active_sequential_hypothesis_testing.pdf">Latest word on active hypothesis testing</a></p>
</li>
</ul>
<h3>Bandit Learning</h3>
<ul>
<li><p>Thompson sampling: A tutorial (distributed via email)</p>
</li>
<li><p></p>
</li>
</ul>
<h1>Lecture Notes</h1>
<p><a href="docs/lecture_note_template.zip">Lecture note template</a></p>
<div id="footer">
<div id="footer-text">
Page generated 2017-04-04 23:59:59 Central Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
